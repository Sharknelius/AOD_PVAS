{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'models\\yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:02<00:00, 2.17MB/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# Define source and destination paths\n",
    "data_dir = os.path.join(os.path.abspath('..'), 'data', 'config.yaml')\n",
    "video_dir = os.path.join(os.path.abspath('..'), 'data', 'videos', 'sample.mp4' )\n",
    "model = YOLO(\"./models/yolo11n.pt\")\n",
    "#model = './models/license_plate_detector.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video\n",
    "cap = cv2.VideoCapture(video_dir)\n",
    "\n",
    "vehicles = [2, 3, 5, 7] # Detect [car, motorbike, bus, truck]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12 cars, 2 buss, 4 trucks, 401.9ms\n",
      "Speed: 5.3ms preprocess, 401.9ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 3 trucks, 123.3ms\n",
      "Speed: 4.0ms preprocess, 123.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 3 trucks, 104.8ms\n",
      "Speed: 1.8ms preprocess, 104.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 3 trucks, 120.5ms\n",
      "Speed: 0.7ms preprocess, 120.5ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 3 trucks, 157.8ms\n",
      "Speed: 0.0ms preprocess, 157.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 5 trucks, 197.8ms\n",
      "Speed: 2.8ms preprocess, 197.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 5 trucks, 177.8ms\n",
      "Speed: 5.9ms preprocess, 177.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 5 trucks, 230.8ms\n",
      "Speed: 4.0ms preprocess, 230.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 4 trucks, 156.1ms\n",
      "Speed: 5.0ms preprocess, 156.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 4 trucks, 166.7ms\n",
      "Speed: 4.3ms preprocess, 166.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 bus, 4 trucks, 243.8ms\n",
      "Speed: 4.6ms preprocess, 243.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 5 trucks, 176.5ms\n",
      "Speed: 4.5ms preprocess, 176.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 4 trucks, 154.4ms\n",
      "Speed: 5.7ms preprocess, 154.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 5 trucks, 191.6ms\n",
      "Speed: 8.3ms preprocess, 191.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 5 trucks, 255.1ms\n",
      "Speed: 5.9ms preprocess, 255.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 5 trucks, 176.1ms\n",
      "Speed: 1.5ms preprocess, 176.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 4 trucks, 175.1ms\n",
      "Speed: 5.4ms preprocess, 175.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 5 trucks, 180.3ms\n",
      "Speed: 8.8ms preprocess, 180.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 5 trucks, 175.6ms\n",
      "Speed: 5.9ms preprocess, 175.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 5 trucks, 168.2ms\n",
      "Speed: 0.6ms preprocess, 168.2ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "frame_nmr = -1\n",
    "ret = True\n",
    "while ret:\n",
    "    frame_nmr += 1\n",
    "    ret, frame = cap.read()\n",
    "    #if ret and frame_nmr < 20: # uncomment this and comment the next line for short testing\n",
    "    if ret and frame_nmr < 20: # Change to just \"if ret\"\n",
    "        results[frame_nmr] = {}\n",
    "        #detect vehicles\n",
    "        detections = model(frame)[0]\n",
    "        detections_ = [] # bounding boxes\n",
    "        for detection in detections.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = detection\n",
    "            if int(class_id) in vehicles:\n",
    "                detections_.append([x1, y1, x2, y2, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old model training code\n",
    "train_results = model.train(\n",
    "    data=data_dir,  # path to dataset YAML\n",
    "    epochs=1,  # number of training epochs\n",
    "    imgsz=640,  # training image size\n",
    "    device=\"cpu\",  # device to run on\n",
    ")\n",
    "\n",
    "# Evaluate model performance on the validation set\n",
    "metrics = model.val()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
